# Innokentiy - Речевой ассистент и виртуальный подкаст

Многофункциональная система на основе технологий машинного обучения, которая объединяет два основных режима работы:

1. **Речевой ассистент** - слушает ключевые слова, записывает речь пользователя и отвечает на неё
2. **Виртуальный подкаст** - генерирует многопользовательские дискуссии на заданные темы

## Особенности

### Речевой ассистент
- **Детекция ключевых слов**: Использует Vosk для распознавания wake words
- **Распознавание речи**: FasterWhisper для точного преобразования речи в текст
- **Интеграция с LLM**: Поддержка локальных языковых моделей через LMStudio API
- **Синтез речи**: Silero TTS для естественного озвучивания текста
- **Интеллектуальная детекция пауз**: Автоматическое определение окончания фразы
- **Поддержка нескольких ключевых слов**: Настраиваемый список слов для активации
- **Сохранение контекста диалога**: Ведение истории разговора с пользователем

### Виртуальный подкаст
- **Многопользовательские дискуссии**: ИИ-персонажи с уникальными ролями и экспертизой
- **Автоматическая оркестрация**: Интеллектуальное управление очередностью выступлений
- **Обогащение контекста**: Автоматический поиск релевантной информации по теме
- **Персонализированные голоса**: Разные голоса для каждого участника
- **Экспорт результатов**: Сохранение в текстовом и аудио форматах
- **Гибкая настройка**: Настраиваемые участники, количество раундов и форматы вывода

### Общие возможности
- **Конфигурируемость**: Гибкая настройка через JSON конфигурацию
- **Фильтрация контента**: Удаление внутренних рассуждений LLM из финального вывода
- **Поддержка акцентизации**: Автоматическая расстановка ударений в русском тексте

## Архитектура

### Основные компоненты

#### Речевой ассистент
- **`main.py`** - Главный файл приложения с классом `SpeechAssistant`
- **`core/wake_word.py`** - Детектор ключевых слов на основе Vosk
- **`core/speech_recognition.py`** - Распознаватель речи с использованием FasterWhisper
- **`core/pause_detection.py`** - Детектор пауз в речи

#### Виртуальный подкаст
- **`virtual_podcast.py`** - Главный файл генератора подкастов
- **`podcast/orchestrator.py`** - Основной оркестратор подкаста
- **`podcast/session.py`** - Управление сессиями подкаста
- **`podcast/persona.py`** - Управление участниками и их персонами
- **`podcast/context_enricher.py`** - Обогащение контекста темы
- **`podcast/context_splitter.py`** - Распределение контекста между участниками

#### Общие компоненты
- **`core/llm_engine.py`** - Движок для работы с локальными языковыми моделями
- **`core/text_to_speech.py`** - Синтезатор речи на основе Silero TTS
- **`utils/`** - Вспомогательные утилиты и конфигурация

### Состояния систем

#### Речевой ассистент
1. **LISTENING** - Ожидание ключевого слова
2. **RECORDING** - Запись речи пользователя
3. **TRANSCRIBING** - Распознавание записанной речи
4. **THINKING** - Обработка текста с помощью LLM
5. **SYNTHESIZING** - Синтез и воспроизведение ответа

#### Виртуальный подкаст
1. **Инициализация** - Создание участников и обогащение контекста
2. **Открытие** - Приветствие модератора и представление темы
3. **Раунды обсуждения** - Поочередные выступления участников
4. **Завершение** - Резюме и заключительные слова модератора
5. **Сохранение** - Экспорт результатов в файлы

## Установка

### Требования

- Python 3.8+
- CUDA-совместимая видеокарта (опционально, для ускорения)
- LMStudio или другой совместимый сервер локальных языковых моделей (опционально)

### Зависимости

```bash
pip install -r requirements.txt
```

### Модель Vosk

Скачайте русскую модель Vosk:

```bash
wget https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip
unzip vosk-model-small-ru-0.22.zip
```

## Конфигурация

Настройки находятся в файле `config.json`:

### Ключевые параметры

```json
{
  "wake_word": {
    "keywords": ["иннокентий", "вергилий"],
    "model_path": "vosk-model-small-ru-0.22",
    "sample_rate": 16000,
    "pre_trigger_duration": 3.0
  },
  "transcription": {
    "whisper_model": "medium",
    "language": "ru",
    "device": "auto"
  },
  "assistant": {
    "max_recording_duration": 20,
    "tts_speaker": "aidar",
    "tts_sample_rate": 48000,
    "use_accentizer": true
  },
  "llm": {
    "enabled": true,
    "base_url": "http://127.0.0.1:1234/v1",
    "model": "local-model",
    "temperature": 0.7
  },
  "podcast": {
    "default_rounds": 3,
    "default_output_format": "both",
    "search_enabled": true,
    "max_search_results": 5
  }
}
```

### Настройка ключевых слов

В секции `wake_word.keywords` можно указать список слов для активации ассистента:

```json
"keywords": ["иннокентий", "вергилий", "ассистент"]
```

### Настройка языковой модели

Секция `llm` управляет интеграцией с локальной языковой моделью:

- `enabled` - включить/выключить использование LLM (при отключении ассистент просто повторяет распознанный текст)
- `base_url` - адрес LMStudio сервера
- `model` - название модели (обычно "local-model" для LMStudio)
- `temperature` - творческий параметр модели (0.1-1.0)

### Настройка синтеза речи

- `tts_speaker` - голос диктора (aidar, baya, kseniya, xenia, eugene, tatyana)
- `use_accentizer` - использование автоматической расстановки ударений

### Настройка подкастов

- `default_rounds` - количество раундов обсуждения по умолчанию
- `default_output_format` - формат вывода ("text", "audio", "both")
- `search_enabled` - включение поиска информации в интернете
- `max_search_results` - максимальное количество результатов поиска

## Использование

### Речевой ассистент

#### Запуск
```bash
python main.py
```

#### Опции командной строки
```bash
python main.py --debug    # Включить отладочный режим
python main.py --help     # Показать справку
```

#### Процесс работы
1. Запустите LMStudio и загрузите языковую модель (опционально)
2. Запустите программу
3. Произнесите одно из ключевых слов (например, "Иннокентий")
4. После звукового сигнала произнесите вашу фразу
5. Ассистент распознает речь, обработает её через LLM и озвучит ответ
6. Система автоматически вернется к ожиданию ключевого слова

### Виртуальный подкаст

#### Быстрый старт
```bash
# Базовый подкаст на 3 раунда с аудио
python virtual_podcast.py --topic "Искусственный интеллект"

# Короткий подкаст только с текстом
python virtual_podcast.py --topic "Будущее работы" --rounds 2 --no-audio

# Интерактивный режим (ввод темы в процессе)
python virtual_podcast.py
```

#### Опции командной строки
```bash
python virtual_podcast.py --topic ТЕМА            # Тема подкаста
python virtual_podcast.py --rounds N              # Количество раундов
python virtual_podcast.py --no-audio              # Только текст, без аудио
python virtual_podcast.py --output-dir PATH       # Директория сохранения
python virtual_podcast.py --help                  # Показать справку
```

#### Участники подкаста по умолчанию
- **Максим** (модератор) - опытный журналист, ведет дискуссию
- **Анна** (техэксперт) - IT-специалист, фокус на технических аспектах
- **Дмитрий** (бизнес-аналитик) - стратег и экономист, бизнес-перспектива

#### Результаты подкаста
После завершения в указанной директории создаются:
- `transcript.json` - полный транскрипт в структурированном формате
- `transcript.md` - человекочитаемый транскрипт
- `*.wav` - аудиофайлы для каждого сегмента (если включен аудио режим)

## Технические детали

### Используемые технологии

- **[Vosk](https://alphacephei.com/vosk/)** - Распознавание ключевых слов в реальном времени
- **[FasterWhisper](https://github.com/guillaumekln/faster-whisper)** - Быстрое и точное распознавание речи
- **[LMStudio](https://lmstudio.ai/)** - Запуск локальных языковых моделей
- **[OpenAI API](https://platform.openai.com/docs/api-reference)** - Совместимый интерфейс для работы с LLM
- **[Silero TTS](https://github.com/snakers4/silero-models)** - Качественный синтез русской речи
- **[RUAccent](https://github.com/TatianaShavrina/RUAccent)** - Автоматическая расстановка ударений

### Особенности реализации

- **Pre-trigger буфер**: Сохраняет аудио до обнаружения ключевого слова для лучшего качества записи
- **Интеллектуальная обработка диалогов**: Поддержка контекста разговора через LLM
- **Fallback режим**: При недоступности LLM ассистент продолжает работать, повторяя распознанный текст
- **Адаптивная детекция пауз**: Интеллектуальное определение окончания речи
- **Асинхронная обработка**: Многопоточная архитектура для плавной работы
- **Автоопределение устройств**: Автоматический выбор CUDA/CPU для оптимальной производительности

### Детекция пауз

Система использует анализ энергии сигнала для определения пауз в речи:
- Минимальная длительность записи: 0.5 сек
- Порог паузы: 2.0 сек тишины
- Максимальная длительность записи: 20 сек

## Разработка

### Структура проекта

```
assistant/
├── main.py                 # Речевой ассистент
├── virtual_podcast.py      # Генератор виртуальных подкастов
├── config.json            # Конфигурация
├── requirements.txt       # Зависимости
├── core/                  # Основные модули
│   ├── __init__.py        # Инициализация модуля
│   ├── wake_word.py       # Детекция ключевых слов
│   ├── speech_recognition.py  # Распознавание речи
│   ├── llm_engine.py      # Движок языковых моделей
│   ├── text_to_speech.py  # Синтез речи
│   └── pause_detection.py # Детекция пауз
├── podcast/               # Модуль виртуальных подкастов
│   ├── __init__.py        # Инициализация модуля
│   ├── orchestrator.py    # Основной оркестратор
│   ├── session.py         # Управление сессиями
│   ├── persona.py         # Участники и персоны
│   ├── context_enricher.py # Обогащение контекста
│   └── context_splitter.py # Распределение контекста
├── utils/                 # Утилиты
│   ├── __init__.py        # Инициализация модуля
│   ├── config.py          # Загрузка конфигурации
│   ├── config_keys.py     # Константы ключей конфигурации
│   ├── enums.py          # Перечисления состояний
│   ├── text_filters.py   # Фильтрация текста LLM
│   ├── logger.py         # Система логирования
│   └── audio_utils.py    # Аудио утилиты
├── output/               # Результаты подкастов
└── vosk-model-small-ru-0.22/  # Модель Vosk
```

### Добавление новых функций

#### Речевой ассистент
1. **Новые ключевые слова**: Добавьте слова в `config.json` → `wake_word.keywords`
2. **Новые голоса**: Измените `config.json` → `assistant.tts_speaker`
3. **Настройка LLM**: Измените параметры в секции `llm` для подключения к другим моделям
4. **Настройка чувствительности**: Измените параметры в секции `voice_detection`

#### Виртуальный подкаст
1. **Новые участники**: Создайте персон в `podcast/persona.py` с уникальными характеристиками
2. **Кастомные голоса**: Назначьте различные голоса участникам в настройках персон
3. **Новые источники контекста**: Расширьте `podcast/context_enricher.py` для других API
4. **Дополнительные форматы экспорта**: Модифицируйте методы сохранения в `podcast/orchestrator.py`

## Устранение неполадок

### Общие проблемы

1. **Модель Vosk не найдена**
   - Убедитесь, что модель скачана и путь в конфигурации корректный

2. **Не работает микрофон**
   - Проверьте права доступа к микрофону
   - Убедитесь, что микрофон не используется другими приложениями

3. **Медленная работа**
   - Установите CUDA для ускорения
   - Уменьшите размер модели Whisper в конфигурации

4. **Плохое качество распознавания**
   - Убедитесь в хорошем качестве микрофона
   - Уменьшите фоновый шум
   - Увеличьте размер модели Whisper

5. **LLM не отвечает или работает медленно**
   - Убедитесь, что LMStudio запущен и модель загружена
   - Проверьте адрес `base_url` в конфигурации
   - Попробуйте уменьшить параметр `temperature`

6. **Проблемы с виртуальным подкастом**
   - Убедитесь, что LLM сервер доступен для обработки множественных запросов
   - Проверьте права доступа к директории вывода
   - При проблемах с интернет-поиском отключите `search_enabled` в конфигурации

### Отладка

#### Речевой ассистент
```bash
python main.py --debug
```

#### Виртуальный подкаст
```bash
# Отладка через подробные логи в консоли
python virtual_podcast.py --topic "Тест" --no-audio

# Проверка конфигурации
python -c "from utils.config import load_config; print(load_config())"
```

## Лицензия

Этот проект использует открытые модели и библиотеки. Убедитесь в совместимости лицензий при коммерческом использовании.

## Авторы

Проект разработан с использованием современных технологий машинного обучения для создания интуитивного речевого интерфейса и генерации многопользовательских дискуссий.