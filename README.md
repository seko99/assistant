# Innokentiy - Речевой ассистент

Речевой ассистент на основе технологий машинного обучения, который слушает ключевые слова, записывает речь пользователя и воспроизводит её обратно с помощью синтеза речи.

## Особенности

- **Детекция ключевых слов**: Использует Vosk для распознавания wake words
- **Распознавание речи**: FasterWhisper для точного преобразования речи в текст
- **Синтез речи**: Silero TTS для естественного озвучивания текста
- **Интеллектуальная детекция пауз**: Автоматическое определение окончания фразы
- **Поддержка нескольких ключевых слов**: Настраиваемый список слов для активации
- **Конфигурируемость**: Гибкая настройка через JSON конфигурацию

## Архитектура

### Основные компоненты

- **`main.py`** - Главный файл приложения с классом `SpeechAssistant`
- **`core/wake_word.py`** - Детектор ключевых слов на основе Vosk
- **`core/speech_recognition.py`** - Распознаватель речи с использованием FasterWhisper
- **`core/text_to_speech.py`** - Синтезатор речи на основе Silero TTS
- **`core/pause_detection.py`** - Детектор пауз в речи
- **`utils/`** - Вспомогательные утилиты и конфигурация

### Состояния системы

Ассистент работает в следующих состояниях:

1. **LISTENING** - Ожидание ключевого слова
2. **RECORDING** - Запись речи пользователя
3. **TRANSCRIBING** - Распознавание записанной речи
4. **SYNTHESIZING** - Синтез и воспроизведение ответа

## Установка

### Требования

- Python 3.8+
- CUDA-совместимая видеокарта (опционально, для ускорения)

### Зависимости

```bash
pip install -r requirements.txt
```

### Модель Vosk

Скачайте русскую модель Vosk:

```bash
wget https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip
unzip vosk-model-small-ru-0.22.zip
```

## Конфигурация

Настройки находятся в файле `config.json`:

### Ключевые параметры

```json
{
  "wake_word": {
    "keywords": ["иннокентий", "вергилий"],
    "model_path": "vosk-model-small-ru-0.22",
    "sample_rate": 16000,
    "pre_trigger_duration": 3.0
  },
  "transcription": {
    "whisper_model": "medium",
    "language": "ru",
    "device": "auto"
  },
  "assistant": {
    "max_recording_duration": 20,
    "tts_speaker": "aidar",
    "tts_sample_rate": 48000,
    "use_accentizer": true
  }
}
```

### Настройка ключевых слов

В секции `wake_word.keywords` можно указать список слов для активации ассистента:

```json
"keywords": ["иннокентий", "вергилий", "ассистент"]
```

### Настройка синтеза речи

- `tts_speaker` - голос диктора (aidar, baya, kseniya, xenia, eugene, tatyana)
- `use_accentizer` - использование автоматической расстановки ударений

## Использование

### Запуск

```bash
python main.py
```

### Опции командной строки

```bash
python main.py --debug    # Включить отладочный режим
python main.py --help     # Показать справку
```

### Процесс работы

1. Запустите программу
2. Произнесите одно из ключевых слов (например, "Иннокентий")
3. После звукового сигнала произнесите вашу фразу
4. Ассистент распознает речь и воспроизведет её обратно
5. Система автоматически вернется к ожиданию ключевого слова

## Технические детали

### Используемые технологии

- **[Vosk](https://alphacephei.com/vosk/)** - Распознавание ключевых слов в реальном времени
- **[FasterWhisper](https://github.com/guillaumekln/faster-whisper)** - Быстрое и точное распознавание речи
- **[Silero TTS](https://github.com/snakers4/silero-models)** - Качественный синтез русской речи
- **[RUAccent](https://github.com/TatianaShavrina/RUAccent)** - Автоматическая расстановка ударений

### Особенности реализации

- **Pre-trigger буфер**: Сохраняет аудио до обнаружения ключевого слова для лучшего качества записи
- **Адаптивная детекция пауз**: Интеллектуальное определение окончания речи
- **Асинхронная обработка**: Многопоточная архитектура для плавной работы
- **Автоопределение устройств**: Автоматический выбор CUDA/CPU для оптимальной производительности

### Детекция пауз

Система использует анализ энергии сигнала для определения пауз в речи:
- Минимальная длительность записи: 0.5 сек
- Порог паузы: 2.0 сек тишины
- Максимальная длительность записи: 20 сек

## Разработка

### Структура проекта

```
innokentiy/
├── main.py                 # Основное приложение
├── config.json            # Конфигурация
├── requirements.txt       # Зависимости
├── core/                  # Основные модули
│   ├── wake_word.py       # Детекция ключевых слов
│   ├── speech_recognition.py  # Распознавание речи
│   ├── text_to_speech.py  # Синтез речи
│   └── pause_detection.py # Детекция пауз
├── utils/                 # Утилиты
│   ├── config.py          # Загрузка конфигурации
│   ├── config_keys.py     # Константы ключей конфигурации
│   ├── enums.py          # Перечисления состояний
│   └── audio_utils.py    # Аудио утилиты
└── vosk-model-small-ru-0.22/  # Модель Vosk
```

### Добавление новых функций

1. **Новые ключевые слова**: Добавьте слова в `config.json` → `wake_word.keywords`
2. **Новые голоса**: Измените `config.json` → `assistant.tts_speaker`
3. **Настройка чувствительности**: Измените параметры в секции `voice_detection`

## Устранение неполадок

### Общие проблемы

1. **Модель Vosk не найдена**
   - Убедитесь, что модель скачана и путь в конфигурации корректный

2. **Не работает микрофон**
   - Проверьте права доступа к микрофону
   - Убедитесь, что микрофон не используется другими приложениями

3. **Медленная работа**
   - Установите CUDA для ускорения
   - Уменьшите размер модели Whisper в конфигурации

4. **Плохое качество распознавания**
   - Убедитесь в хорошем качестве микрофона
   - Уменьшите фоновый шум
   - Увеличьте размер модели Whisper

### Отладка

Запустите с флагом `--debug` для получения подробных логов:

```bash
python main.py --debug
```

## Лицензия

Этот проект использует открытые модели и библиотеки. Убедитесь в совместимости лицензий при коммерческом использовании.

## Авторы

Проект разработан с использованием современных технологий машинного обучения для создания интуитивного речевого интерфейса.