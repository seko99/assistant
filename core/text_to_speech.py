"""
Text-to-speech module using Silero TTS.
"""

import time
import os
from pathlib import Path
from typing import Optional, Union

import sounddevice as sd
import torch
import torchaudio

from utils.config_keys import ConfigKeys, ConfigSections
from utils.logger import get_logger


class TextToSpeech:
    """–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ Silero TTS"""

    def __init__(self, config):
        self.config = config
        self.assistant_config = config[ConfigSections.ASSISTANT]
        self.model = None
        self.sample_rate = self.assistant_config[ConfigKeys.TTS.TTS_SAMPLE_RATE]
        self.speaker = self.assistant_config[ConfigKeys.TTS.TTS_SPEAKER]
        self.use_accentizer = self.assistant_config.get(ConfigKeys.TTS.USE_ACCENTIZER, False)
        self.playback_device = self.assistant_config.get('playback_device', None)
        self.offline_mode = False  # –§–ª–∞–≥ –¥–ª—è –æ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º–∞
        self.accentizer = None
        self.logger = get_logger('tts')

    def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Silero TTS —Å graceful fallback"""
        try:
            self.logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ Silero TTS...")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞ –º–æ–¥–µ–ª–∏
            model_loaded = False

            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            try:
                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
                self.model, example_text = torch.hub.load(
                    repo_or_dir='snakers4/silero-models',
                    model='silero_tts',
                    language='ru',
                    speaker='ru_v3',
                    force_reload=False  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à –µ—Å–ª–∏ –µ—Å—Ç—å
                )
                self.model.to(device)
                model_loaded = True
                self.logger.info("–ú–æ–¥–µ–ª—å Silero —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

            except Exception as model_error:
                self.logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ Silero: {model_error}")
                self.logger.warning("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π –∫—ç—à")

                # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –æ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º–µ
                self.offline_mode = True
                self.logger.info("–ü–µ—Ä–µ—Ö–æ–¥ –≤ –æ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º (—Ç–æ–ª—å–∫–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª)")

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–∫—Ü–µ–Ω—Ç–∏–∑–∞—Ç–æ—Ä –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if self.use_accentizer and not self.offline_mode:
                try:
                    from ruaccent import RUAccent
                    self.accentizer = RUAccent()
                    self.accentizer.load(omograph_model_size='turbo', use_dictionary=True)
                    self.logger.info("RUAccent –∑–∞–≥—Ä—É–∂–µ–Ω")
                except ImportError:
                    self.logger.warning("RUAccent –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —Å–∏–Ω—Ç–µ–∑ –±–µ–∑ —É–¥–∞—Ä–µ–Ω–∏–π")
                    self.use_accentizer = False
                except Exception as accent_error:
                    self.logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ RUAccent: {accent_error}")
                    self.use_accentizer = False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
            if not self.offline_mode:
                self._check_audio_device()

            if model_loaded:
                self.logger.info(f"Silero TTS –≥–æ—Ç–æ–≤ (–¥–∏–Ω–∞–º–∏–∫: {self.speaker})")
            else:
                self.logger.warning("TTS —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ")

            return True  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º True –¥–∞–∂–µ –≤ –æ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º–µ

        except Exception as e:
            self.logger.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ TTS: {e}")
            return False

    def synthesize_and_play(self, text, voice_override: Optional[str] = None, save_path: Optional[str] = None):
        """
        –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç –∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç —Ä–µ—á—å

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞
            voice_override: –ì–æ–ª–æ—Å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
            save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        if self.offline_mode:
            self.logger.warning("–û—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º: —Å–∏–Ω—Ç–µ–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ synthesize_only.")
            return False

        if not self.model or not text.strip():
            return False

        start_time = time.time()
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ–ª–æ—Å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            speaker_to_use = voice_override if voice_override else self.speaker

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –∞–∫—Ü–µ–Ω—Ç–∏–∑–∞—Ç–æ—Ä–æ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            processed_text = text
            if self.use_accentizer and self.accentizer:
                processed_text = self.accentizer.process_all(text)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—É–¥–∏–æ
            audio = self.model.apply_tts(
                text=processed_text,
                speaker=speaker_to_use,
                sample_rate=self.sample_rate
            )

            audio_np = audio.detach().cpu().numpy()
            synthesis_time = time.time() - start_time
            self.logger.info(f"–°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º ({speaker_to_use}): {text} (–≤—Ä–µ–º—è: {synthesis_time:.3f}s)")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å
            if save_path:
                self._save_audio_file(audio, save_path)
                self.logger.info(f"–ê—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {save_path}")

            # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –≤ –æ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º–µ
            if not self.offline_mode:
                try:
                    device_id = self.playback_device if self.playback_device is not None else sd.default.device[1]
                    sd.play(audio_np, self.sample_rate, device=device_id)
                    sd.wait()  # –ñ–¥–µ–º –æ–∫–æ–Ω—á–∞–Ω–∏—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
                except Exception as audio_error:
                    self.logger.error(f"–û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ: {audio_error}")
                    return False
            else:
                self.logger.info("–û—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º: –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ")

            return True

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {e}")
            return False

    def synthesize_only(self, text, voice_override: Optional[str] = None, save_path: Optional[str] = None):
        """
        –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ä–µ—á—å –±–µ–∑ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è (–¥–ª—è —Ä–µ–∂–∏–º–∞ --no-audio)

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞
            voice_override: –ì–æ–ª–æ—Å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            save_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞

        Returns:
            –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –∏–ª–∏ None
        """
        if not self.model or not text.strip():
            return None

        start_time = time.time()
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ–ª–æ—Å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            speaker_to_use = voice_override if voice_override else self.speaker

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –∞–∫—Ü–µ–Ω—Ç–∏–∑–∞—Ç–æ—Ä–æ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            processed_text = text
            if self.use_accentizer and self.accentizer:
                processed_text = self.accentizer.process_all(text)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—É–¥–∏–æ
            audio = self.model.apply_tts(
                text=processed_text,
                speaker=speaker_to_use,
                sample_rate=self.sample_rate
            )

            synthesis_time = time.time() - start_time
            print(f"üîÑ –°–∏–Ω—Ç–µ–∑ ({speaker_to_use}): {text} (–≤—Ä–µ–º—è: {synthesis_time:.3f}s)")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            if save_path:
                self._save_audio_file(audio, save_path)
                self.logger.info(f"–ê—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {save_path}")
                return save_path

            return None

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {e}")
            return None

    def _check_audio_device(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤"""
        try:
            if self.playback_device is not None:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–∫–∞–∑–∞–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
                devices = sd.query_devices()
                if self.playback_device >= len(devices):
                    print(f"‚ö†Ô∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {self.playback_device} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
                    self.playback_device = None
                else:
                    device_info = devices[self.playback_device]
                    print(f"üîä –ê—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device_info['name']}")
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                default_device = sd.default.device[1]
                device_info = sd.query_devices(default_device)
                print(f"üîä –ê—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {device_info['name']}")

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {e}")
            self.playback_device = None

    def _save_audio_file(self, audio_tensor, file_path: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—É–¥–∏–æ —Ç–µ–Ω–∑–æ—Ä –≤ —Ñ–∞–π–ª"""
        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            Path(file_path).parent.mkdir(parents=True, exist_ok=True)

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            audio_to_save = audio_tensor.unsqueeze(0) if audio_tensor.dim() == 1 else audio_tensor

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ WAV —Ñ–æ—Ä–º–∞—Ç–µ
            torchaudio.save(file_path, audio_to_save, self.sample_rate)

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            raise