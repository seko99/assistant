"""
Speech recognition module using FasterWhisper.
"""

import os
import time

import soundfile as sf
import torch
from faster_whisper import WhisperModel

from utils.config_keys import ConfigKeys


class SpeechRecognizer:
    """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å —Ä–µ—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ FasterWhisper (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è voice_recorder.py)"""

    def __init__(self, config):
        self.config = config
        self.transcription_config = config[ConfigKeys.TRANSCRIPTION]
        self.whisper_model = None

    def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ FasterWhisper"""
        try:
            model_size = self.transcription_config.get(ConfigKeys.Transcription.WHISPER_MODEL, 'base')
            device = self.transcription_config.get(ConfigKeys.Transcription.DEVICE, 'auto')
            compute_type = self.transcription_config.get(ConfigKeys.Transcription.COMPUTE_TYPE, 'auto')

            # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if device == 'auto' or compute_type == 'auto':
                device, compute_type = self._detect_optimal_settings()

            print(f"üîç –ó–∞–≥—Ä—É–∑–∫–∞ FasterWhisper: {model_size}/{device}/{compute_type}")

            self.whisper_model = WhisperModel(
                model_size,
                device=device,
                compute_type=compute_type
            )

            print(f"‚úÖ FasterWhisper –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ FasterWhisper: {e}")
            return False

    def _detect_optimal_settings(self):
        """–ü—Ä–æ—Å—Ç–æ–µ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA
            if torch.cuda.is_available():
                return "cuda", "float16"
        except:
            pass
        return "cpu", "int8"

    def transcribe_audio(self, audio_data, sample_rate):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç"""
        if not self.whisper_model:
            return ""

        start_time = time.time()
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è FasterWhisper
            temp_filename = f"temp_recording_{int(time.time())}.wav"
            sf.write(temp_filename, audio_data, sample_rate)

            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
            language = self.transcription_config.get(ConfigKeys.Transcription.LANGUAGE, 'ru')
            beam_size = self.transcription_config.get(ConfigKeys.Transcription.BEAM_SIZE, 5)

            segments, info = self.whisper_model.transcribe(
                temp_filename,
                language=language,
                beam_size=beam_size,
                word_timestamps=False
            )

            # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç
            text_segments = []
            for segment in segments:
                text_segments.append(segment.text)

            text = " ".join(text_segments).strip()
            transcription_time = time.time() - start_time

            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            try:
                os.remove(temp_filename)
            except:
                pass

            if text.strip():
                print(f"üìÑ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {text} (–≤—Ä–µ–º—è: {transcription_time:.3f}s)")

            return text

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
            return ""