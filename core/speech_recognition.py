"""
Speech recognition module using FasterWhisper.
"""

import os
import tempfile
import time

import soundfile as sf
import torch
from faster_whisper import WhisperModel

from utils.config_keys import ConfigKeys, ConfigSections


class SpeechRecognizer:
    """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å —Ä–µ—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ FasterWhisper (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è voice_recorder.py)"""

    def __init__(self, config):
        self.config = config
        self.transcription_config = config[ConfigSections.TRANSCRIPTION]
        self.whisper_model = None

    def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ FasterWhisper"""
        try:
            model_size = self.transcription_config.get(ConfigKeys.Transcription.WHISPER_MODEL, 'base')
            device = self.transcription_config.get(ConfigKeys.Transcription.DEVICE, 'auto')
            compute_type = self.transcription_config.get(ConfigKeys.Transcription.COMPUTE_TYPE, 'auto')

            # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if device == 'auto' or compute_type == 'auto':
                device, compute_type = self._detect_optimal_settings()

            print(f"üîç –ó–∞–≥—Ä—É–∑–∫–∞ FasterWhisper: {model_size}/{device}/{compute_type}")

            self.whisper_model = WhisperModel(
                model_size,
                device=device,
                compute_type=compute_type
            )

            print(f"‚úÖ FasterWhisper –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ FasterWhisper: {e}")
            return False

    def _detect_optimal_settings(self):
        """–ü—Ä–æ—Å—Ç–æ–µ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA
            if torch.cuda.is_available():
                return "cuda", "float16"
        except:
            pass
        return "cpu", "int8"

    def transcribe_audio(self, audio_data, sample_rate):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç"""
        if not self.whisper_model:
            return ""

        start_time = time.time()
        temp_file = None

        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
            save_audio_files = self.transcription_config.get('save_audio_files', False)
            auto_delete_audio = self.transcription_config.get('auto_delete_audio', True)

            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if save_audio_files:
                # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ñ–∞–π–ª—ã, —Å–æ–∑–¥–∞–µ–º –≤ —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                temp_filename = f"temp_recording_{int(time.time())}.wav"
                sf.write(temp_filename, audio_data, sample_rate)
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥
                temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
                temp_filename = temp_file.name
                temp_file.close()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª, —á—Ç–æ–±—ã soundfile –º–æ–≥ –∑–∞–ø–∏—Å–∞—Ç—å –≤ –Ω–µ–≥–æ
                sf.write(temp_filename, audio_data, sample_rate)

            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
            language = self.transcription_config.get(ConfigKeys.Transcription.LANGUAGE, 'ru')
            beam_size = self.transcription_config.get(ConfigKeys.Transcription.BEAM_SIZE, 5)

            segments, info = self.whisper_model.transcribe(
                temp_filename,
                language=language,
                beam_size=beam_size,
                word_timestamps=False
            )

            # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç
            text_segments = []
            for segment in segments:
                text_segments.append(segment.text)

            text = " ".join(text_segments).strip()
            transcription_time = time.time() - start_time

            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º
            if auto_delete_audio and not save_audio_files:
                try:
                    os.remove(temp_filename)
                except Exception as cleanup_error:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {temp_filename}: {cleanup_error}")

            if text.strip():
                print(f"üìÑ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {text} (–≤—Ä–µ–º—è: {transcription_time:.3f}s)")

            return text

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
            # –ü—ã—Ç–∞–µ–º—Å—è –æ—á–∏—Å—Ç–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            if temp_file and os.path.exists(temp_file.name):
                try:
                    os.remove(temp_file.name)
                except:
                    pass
            return ""