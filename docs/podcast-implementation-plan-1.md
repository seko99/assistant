1. Вход от пользователя
- Создать скрипт `virtual_podcast.py`, использующий существующую утилиту `load_config` для чтения `config.json` и новой секции `podcast` с описанием модератора, спикеров и настроек сессии (число раундов, включение поиска, формат вывода).
- Реализовать CLI-интерфейс (через `argparse`) с параметрами `--topic`, `--rounds`, `--output-dir` и флагом `--no-audio`; при отсутствии аргумента тема запрашивается интерактивно и сохраняется в объект `PodcastSession`.
- Подготовить структуру данных `PodcastSession` (dataclass) в модуле `podcast/session.py`, содержащую тему, очередь выступлений, историю событий и ссылки на LLM/TTS клиентов.
- Обеспечить минимальные изменения в существующем коде: только расширить `core.llm_engine.LLMEngine` и `core.text_to_speech.TextToSpeech` опциональными параметрами, чтобы их можно было переиспользовать в новом скрипте без дублирования логики.

2. Обогащение контекста
- Реализовать модуль `podcast/context_enricher.py` с классом `PodcastContextEnricher`, который принимает тему и конфигурацию поиска, запрашивает поисковый MCP-сервер (интерфейс `SearchProvider`) и возвращает структурированный контекст: краткий обзор, список фактов, ссылки.
- Добавить в конфигурацию блок `"search"` (тип провайдера, ключи, лимиты запросов). При недоступности сети используем режим `mock` с заранее заданными выдержками или локальными файлами.
- Обновить `virtual_podcast.py`, чтобы модератор инициировал поиск только один раз (до первого круга) и при необходимости по сигналу (`need_refresh` от модератора) повторял запрос.
- Сохранить расширенный контекст в сессии и передавать его в дальнейшие этапы вместе с исходной темой.

3. Подготовка к обсуждению
- Создать модуль `podcast/persona.py` с dataclass-ами `ParticipantProfile` и `SpeakerAssignment`, описывающими голос, личность, системный промпт и специальные инструкции; загрузить их из `config.json`.
- Добавить в `LLMEngine` возможность принимать кастомный системный промпт и отдельную историю диалога: метод `create_session(system_prompt: str)` возвращает объект `LLMSession` с независимой историей и ссылкой на общий клиент (изменения свести к добавлению вспомогательного класса и сохранению обратной совместимости).
- Реализовать распределение контекста: модуль `podcast/context_splitter.py` формирует подсказки для каждого спикера (технический, исторический, пользовательский и т. п.), объединяя тему, факты из поиска и индивидуальные инструкции из профиля.
- Сформировать очередь выступлений (например, `C1 -> C2 -> C3`) и передать её в `PodcastSession`; предусмотреть параметр конфигурации для количества раундов или пользовательский ввод.

4. Ход подкаста
- Создать модуль `podcast/orchestrator.py` с классом `PodcastOrchestrator`, который управляет сценарием: открытие модератора, последовательные выступления спикеров, короткие связки модератора и опциональные повторные поисковые запросы.
- Для каждого участника использовать отдельный `LLMSession`: модератор формирует вопросы и комментарии, спикеры отвечают согласно своему контексту; сохранять реплики в `PodcastSession.transcript`.
- Расширить `TextToSpeech.synthesize_and_play` аргументами `voice_override` и `save_path`, позволяя выбирать голос динамически и записывать треки в файлы (`output/<timestamp>/<speaker>.wav`). Изменения ограничить условными параметрами без затрагивания основного сценария `main.py`.
- Реализовать в оркестраторе опцию `--no-audio`, при которой вместо воспроизведения аудио сохраняется только текст; иначе после генерации ответа выполняется синтез и последовательное проигрывание.
- Добавить обработку ошибок: таймауты LLM, отсутствие результатов поиска, проблемы TTS; при сбое выдавать fallback (например, текст без озвучки) и логировать в `PodcastSession.events`.

5. Завершение
- После завершения заданного числа раундов модератор формирует итоговое резюме, используя свою `LLMSession` и полный транскрипт; дополнительно создать краткий bullet-point конспект (`summary.md`).
- Сохранить полный сценарий в `output/<timestamp>/transcript.json` (структура: участник, текст, аудио-файл, источники контекста) и человекочитаемую версию `transcript.md`.
- Предусмотреть генерацию дополнительного отчёта (по желанию) — например, `key_takeaways` через отдельный запрос к LLM с повышенной температурой.
- Вернуть путь к сохранённым материалам в stdout скрипта; предусмотреть unit-тест для сериализации транскрипта.

6. Дополнительные возможности
- Настроить управление голосами: в конфигурации для каждого спикера указать Silero-голос, скорость, громкость; при необходимости добавить нормализацию громкости в `utils/audio_utils.py`.
- Добавить поддержку «живых» исследований: модератор может инициировать дополнительный поиск, если в ответе спикера обнаружен маркер (`[[fact-check]]`), реализовав простой анализ текста.
- Реализовать возможность смены модели LLM для отдельных ролей (например, у модератора более строгий системный промпт) через конфигурацию `podcast.llm_overrides`.
- Подготовить минимальный набор тестов (pytest): проверка распределения контекста, корректность очередности реплик, генерация файлов при `--no-audio` и `--rounds=1`.
